#!/bin/sh

#
# Run parameters
export TMPL=$HADOOP_HOME/../conf/conf-personal/genepool/
export HADOOP_LOG_DIR=$SCRATCH/logs/
export HADOOP_PID_DIR=$SCRATCH/logs/pids/
export EXT="-nohdfs"

if [ ! -e $HADOOP_CONF_DIR ] ; then
  ip=$( host $(hostname)|sed 's/.* //')
  port=$(( 100+( $(od -An -N2 -i /dev/random) )%(40000-1024+1) ))
  while :
  do
    (echo >/dev/tcp/localhost/$port) &>/dev/null &&  port=$(( 100+( $(od -An -N2 -i /dev/random) )%(40000-1000+1) )) || break
  done
  IP=$ip":"$port
  mkdir $HADOOP_CONF_DIR
  for file in "mapred" "core" "hdfs"; do
    cat $TMPL/$file-site${EXT}.xml.tmpl | \
          sed "s|%IP%|$IP|"| \
          sed "s|%SCRATCH%|$SCRATCH|"| \
          sed "s|%USER%|$USER|" > $HADOOP_CONF_DIR/$file-site.xml
  done
fi

hadoop-daemon.sh start jobtracker

#
# If we need to get stat of the jobtracker
#
# hadoop-daemon.sh start jobtracker &
# PID1=$!
# python zmq_monitor_client.py -s <server_ip> -p <server_port> -d <interval(sec)> -i $PID1 &
# PID2=$!
# wait $PID1 &&
# kill -9 $PID2

#
# NOTE: Before run "zmq_monitor_client.py", please run "zmq_monitor_server.py" 
# on other terminal and set server ip, port, interval.
#
